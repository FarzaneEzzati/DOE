{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-13T18:57:40.937291600Z",
     "start_time": "2024-02-13T18:57:36.225496300Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers, Model\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from tensorflow.python.framework.ops import enable_eager_execution\n",
    "enable_eager_execution()\n",
    "\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for gpu in gpus:\n",
    "# tf.config.experimental.reset_memory_stats(gpu, True)\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Flatten, Reshape, LeakyReLU, Dropout, UpSampling2D, ConvLSTM1D, LSTM\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.models import Model\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "my_data = pd.read_csv('HarrisCounty/ForGAN/JulAug.csv')\n",
    "ds_w = []\n",
    "ds_e = []\n",
    "for c in my_data.columns:\n",
    "    if 'weekday' in c:\n",
    "        ds_w.append(my_data[c].values)\n",
    "    else:\n",
    "        ds_e.append(my_data[c].values)\n",
    "\n",
    "max_w =  np.max(ds_w)\n",
    "max_e = np.max(ds_e)\n",
    "ds_w = np.divide(ds_w, 1.1 * max_w)\n",
    "ds_e = np.divide(ds_e, 1.1 * max_e)\n",
    "ds_w1 = ds_w\n",
    "ds_w = tf.data.Dataset.from_tensor_slices(ds_w)\n",
    "ds_e = tf.data.Dataset.from_tensor_slices(ds_e)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T19:49:15.911310500Z",
     "start_time": "2024-02-13T19:49:15.864242100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "(96,)"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_w.as_numpy_iterator().next().shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T19:27:52.702312400Z",
     "start_time": "2024-02-13T19:27:52.678902500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare data to feed into GAN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "batch_size = 15\n",
    "ds_w = ds_w.cache()\n",
    "ds_w = ds_w.shuffle(1000)\n",
    "ds_w = ds_w.batch(batch_size)\n",
    "ds_w = ds_w.prefetch(64)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T19:49:18.281782900Z",
     "start_time": "2024-02-13T19:49:18.271132200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generator Discriminator Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_72 (LSTM)              (None, 96, 5)             420       \n",
      "                                                                 \n",
      " leaky_re_lu_59 (LeakyReLU)  (None, 96, 5)             0         \n",
      "                                                                 \n",
      " lstm_73 (LSTM)              (None, 96, 5)             220       \n",
      "                                                                 \n",
      " leaky_re_lu_60 (LeakyReLU)  (None, 96, 5)             0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 96, 1)             6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 646\n",
      "Trainable params: 646\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "g_relu = 0.1\n",
    "lstm_unit = 5\n",
    "def build_generator():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_unit, activation='tanh', return_sequences=True,\n",
    "               input_shape=(96, batch_size)))  # returns a sequence of vectors of dimension lstm_unit\n",
    "    model.add(LeakyReLU(d_relu))\n",
    "\n",
    "    model.add(LSTM(lstm_unit, return_sequences=True))  # returns a sequence of vectors of dimension lstm_unit\n",
    "    model.add(LeakyReLU(d_relu))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "generator = build_generator()\n",
    "generator.summary()\n",
    "# plt.plot(generator.predict(np.random.randn(1, 96, 15))[0])\n",
    "#plt.plot(series[0].reshape([96]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T20:21:26.342743700Z",
     "start_time": "2024-02-13T20:21:25.913472400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_74 (LSTM)              (None, 96, 5)             140       \n",
      "                                                                 \n",
      " leaky_re_lu_61 (LeakyReLU)  (None, 96, 5)             0         \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 96, 5)             0         \n",
      "                                                                 \n",
      " lstm_75 (LSTM)              (None, 96, 5)             220       \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 480)               0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 1)                 481       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 841\n",
      "Trainable params: 841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "d_relu = 0.1\n",
    "d_dropout = 0.2\n",
    "def build_discriminator():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(lstm_unit, return_sequences=True,\n",
    "               input_shape=(96, 1)))\n",
    "    model.add(LeakyReLU(d_relu))\n",
    "    model.add(Dropout(d_dropout))\n",
    "\n",
    "    model.add(LSTM(lstm_unit, return_sequences=True,\n",
    "               input_shape=(96, 1)))\n",
    "    model.add(Flatten())\n",
    "    #model.add(Dropout(d_dropout))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "discriminator.summary()\n",
    "# Single prediction needs np.expand_dims(series[0], 0)\n",
    "# discriminator.predict(ds_w.as_numpy_iterator().next())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T20:21:28.624499300Z",
     "start_time": "2024-02-13T20:21:28.189440400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "g_a, d_a = 0.0001, 0.00001\n",
    "g_opt = Adam(learning_rate=g_a)\n",
    "d_opt = Adam(learning_rate=d_a)  # Does not learn too fast\n",
    "g_loss = BinaryCrossentropy()\n",
    "d_loss = BinaryCrossentropy()\n",
    "class LoadGAN(Model):\n",
    "    def __init__(self, generator, discriminator, *args, **kwargs):\n",
    "        # pass through args and kwargs to base class\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # Create attributes for gen and disc\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "\n",
    "    def compilee(self, g_opt, d_opt, g_loss, d_loss, *args, **kwargs):\n",
    "        # Compile with base class\n",
    "        super().compile(*args, **kwargs)\n",
    "\n",
    "        self.g_opt = g_opt\n",
    "        self.d_opt = d_opt\n",
    "        self.g_loss = g_loss\n",
    "        self.d_loss = d_loss\n",
    "\n",
    "    def train_step(self, batch):\n",
    "        real_series = batch\n",
    "        fake_series = self.generator(tf.random.normal((batch_size, 96, batch_size)), training=False)\n",
    "\n",
    "        # train the discriminator\n",
    "        with tf.GradientTape() as d_tape:\n",
    "            # pass the real and fake images\n",
    "            yhat_real = self.discriminator(real_series, training=True)\n",
    "            yhat_fake = self.discriminator(fake_series, training=True)\n",
    "            yhat_realfake = tf.concat([yhat_real, yhat_fake], axis=0)\n",
    "\n",
    "            # create labels for real and fake series\n",
    "            y_realfake = tf.concat([tf.zeros_like(yhat_real), tf.ones_like(yhat_fake)], axis=0)\n",
    "\n",
    "\n",
    "            # pass through and add some noise to the outputs\n",
    "            noise_real = 0.2*tf.random.uniform(tf.shape(yhat_real))\n",
    "            noise_fake = 0.2*tf.random.uniform(tf.shape(yhat_fake))\n",
    "            y_realfake += tf.concat([noise_real, noise_fake], axis=0)\n",
    "\n",
    "            # calculate the loss\n",
    "            total_d_loss = self.d_loss(y_realfake, yhat_realfake)\n",
    "\n",
    "        # apply backpropagation\n",
    "        dgrad = d_tape.gradient(total_d_loss, self.discriminator.trainable_variables)\n",
    "        self.d_opt.apply_gradients(zip(dgrad, self.discriminator.trainable_variables))\n",
    "\n",
    "        # Generator training\n",
    "        with tf.GradientTape() as g_tape:\n",
    "            # generate same new images\n",
    "            gen_series = self.generator(tf.random.normal((batch_size, 96, batch_size)), training=True)\n",
    "\n",
    "            # create the predicted labels\n",
    "            predicted_labels = self.discriminator(gen_series, training=False)\n",
    "\n",
    "            # calculate loss\n",
    "            total_g_loss = self.g_loss(tf.zeros_like(predicted_labels), predicted_labels)\n",
    "\n",
    "        # apply backpropagation\n",
    "        ggrad = g_tape.gradient(total_g_loss, self.generator.trainable_variables)\n",
    "        self.g_opt.apply_gradients(zip(ggrad, self.generator.trainable_variables))\n",
    "\n",
    "        return {\"d_loss\":total_d_loss, \"g_loss\":total_g_loss}\n",
    "loadgan = LoadGAN(generator, discriminator)\n",
    "loadgan.compilee(g_opt, d_opt, g_loss, d_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T20:21:31.295697200Z",
     "start_time": "2024-02-13T20:21:31.249699800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Call Back"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "class ModelMonitor(Callback):\n",
    "    def __init__(self, num_img=4, latent_dim=batch_size):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vector = tf.random.normal((self.num_img, 96, self.latent_dim))\n",
    "        generated_series = self.model.generator(random_latent_vector)\n",
    "        generated_series *= max_w\n",
    "        generated_series.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            serie = generated_series[i]\n",
    "            #serie.save(os.path.join('series', f'generated_img_{epoch}_{i}.png'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T20:21:35.084254100Z",
     "start_time": "2024-02-13T20:21:35.062867Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 30s 2s/step - d_loss: 0.6915 - g_loss: 0.7214\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 28s 2s/step - d_loss: 0.6910 - g_loss: 0.7228\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 28s 2s/step - d_loss: 0.6906 - g_loss: 0.7244\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 24s 2s/step - d_loss: 0.6904 - g_loss: 0.7259\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 21s 2s/step - d_loss: 0.6896 - g_loss: 0.7276\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 22s 2s/step - d_loss: 0.6899 - g_loss: 0.7291\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 28s 2s/step - d_loss: 0.6892 - g_loss: 0.7308\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 28s 2s/step - d_loss: 0.6889 - g_loss: 0.7323\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 30s 2s/step - d_loss: 0.6883 - g_loss: 0.7339\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 28s 2s/step - d_loss: 0.6887 - g_loss: 0.7356\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 24s 2s/step - d_loss: 0.6880 - g_loss: 0.7371\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 23s 2s/step - d_loss: 0.6878 - g_loss: 0.7387\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 24s 2s/step - d_loss: 0.6869 - g_loss: 0.7404\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 33s 3s/step - d_loss: 0.6869 - g_loss: 0.7422\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 27s 2s/step - d_loss: 0.6863 - g_loss: 0.7439\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 25s 2s/step - d_loss: 0.6871 - g_loss: 0.7457\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 26s 2s/step - d_loss: 0.6860 - g_loss: 0.7473\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 32s 2s/step - d_loss: 0.6861 - g_loss: 0.7489\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 26s 2s/step - d_loss: 0.6852 - g_loss: 0.7507\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 29s 2s/step - d_loss: 0.6850 - g_loss: 0.7523\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 29s 2s/step - d_loss: 0.6857 - g_loss: 0.7542\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 27s 2s/step - d_loss: 0.6852 - g_loss: 0.7559\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 32s 2s/step - d_loss: 0.6849 - g_loss: 0.7577\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 27s 2s/step - d_loss: 0.6832 - g_loss: 0.7594\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 29s 2s/step - d_loss: 0.6839 - g_loss: 0.7612\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 34s 3s/step - d_loss: 0.6828 - g_loss: 0.7628\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 33s 3s/step - d_loss: 0.6830 - g_loss: 0.7647\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 34s 3s/step - d_loss: 0.6830 - g_loss: 0.7666\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 29s 2s/step - d_loss: 0.6827 - g_loss: 0.7683\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 30s 2s/step - d_loss: 0.6828 - g_loss: 0.7701\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 29s 2s/step - d_loss: 0.6828 - g_loss: 0.7717\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 35s 3s/step - d_loss: 0.6807 - g_loss: 0.7734\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 33s 3s/step - d_loss: 0.6819 - g_loss: 0.7754\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 29s 2s/step - d_loss: 0.6823 - g_loss: 0.7771\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 29s 2s/step - d_loss: 0.6825 - g_loss: 0.7789\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 31s 2s/step - d_loss: 0.6808 - g_loss: 0.7805\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 28s 2s/step - d_loss: 0.6806 - g_loss: 0.7820\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 25s 2s/step - d_loss: 0.6813 - g_loss: 0.7837\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 33s 2s/step - d_loss: 0.6804 - g_loss: 0.7853\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 24s 2s/step - d_loss: 0.6803 - g_loss: 0.7870\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 38s 3s/step - d_loss: 0.6793 - g_loss: 0.7886\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 41s 3s/step - d_loss: 0.6796 - g_loss: 0.7902\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 43s 3s/step - d_loss: 0.6805 - g_loss: 0.7917\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 27s 2s/step - d_loss: 0.6783 - g_loss: 0.7932\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 41s 3s/step - d_loss: 0.6791 - g_loss: 0.7947\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 40s 3s/step - d_loss: 0.6792 - g_loss: 0.7962\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 42s 3s/step - d_loss: 0.6787 - g_loss: 0.7976\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 41s 3s/step - d_loss: 0.6818 - g_loss: 0.7991\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 42s 3s/step - d_loss: 0.6800 - g_loss: 0.8003\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 42s 3s/step - d_loss: 0.6796 - g_loss: 0.8014\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 41s 3s/step - d_loss: 0.6796 - g_loss: 0.8028\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 41s 3s/step - d_loss: 0.6792 - g_loss: 0.8040\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 42s 3s/step - d_loss: 0.6800 - g_loss: 0.8051\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 24s 2s/step - d_loss: 0.6804 - g_loss: 0.8063\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 23s 2s/step - d_loss: 0.6789 - g_loss: 0.8073\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 23s 2s/step - d_loss: 0.6803 - g_loss: 0.8083\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 23s 2s/step - d_loss: 0.6807 - g_loss: 0.8093\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 23s 2s/step - d_loss: 0.6796 - g_loss: 0.8103\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 24s 2s/step - d_loss: 0.6778 - g_loss: 0.8113\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 28s 2s/step - d_loss: 0.6794 - g_loss: 0.8124\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 25s 2s/step - d_loss: 0.6781 - g_loss: 0.8136\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 31s 2s/step - d_loss: 0.6789 - g_loss: 0.8147\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 31s 2s/step - d_loss: 0.6777 - g_loss: 0.8158\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 28s 2s/step - d_loss: 0.6779 - g_loss: 0.8170\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 24s 2s/step - d_loss: 0.6786 - g_loss: 0.8180\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 32s 3s/step - d_loss: 0.6775 - g_loss: 0.8192\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 28s 2s/step - d_loss: 0.6781 - g_loss: 0.8202\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 28s 2s/step - d_loss: 0.6774 - g_loss: 0.8213\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 26s 2s/step - d_loss: 0.6790 - g_loss: 0.8222\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 26s 2s/step - d_loss: 0.6774 - g_loss: 0.8231\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 30s 2s/step - d_loss: 0.6771 - g_loss: 0.8239\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 32s 2s/step - d_loss: 0.6801 - g_loss: 0.8249\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 29s 2s/step - d_loss: 0.6776 - g_loss: 0.8256\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 28s 2s/step - d_loss: 0.6789 - g_loss: 0.8265\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 24s 2s/step - d_loss: 0.6777 - g_loss: 0.8273\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 27s 2s/step - d_loss: 0.6756 - g_loss: 0.8281\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 30s 2s/step - d_loss: 0.6775 - g_loss: 0.8291\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 30s 2s/step - d_loss: 0.6770 - g_loss: 0.8300\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 27s 2s/step - d_loss: 0.6768 - g_loss: 0.8309\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 29s 2s/step - d_loss: 0.6792 - g_loss: 0.8315\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 27s 2s/step - d_loss: 0.6764 - g_loss: 0.8320\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 30s 2s/step - d_loss: 0.6772 - g_loss: 0.8329\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 28s 2s/step - d_loss: 0.6779 - g_loss: 0.8335\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 40s 3s/step - d_loss: 0.6777 - g_loss: 0.8341\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 42s 3s/step - d_loss: 0.6782 - g_loss: 0.8347\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 40s 3s/step - d_loss: 0.6771 - g_loss: 0.8352\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 40s 3s/step - d_loss: 0.6778 - g_loss: 0.8358\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 42s 3s/step - d_loss: 0.6763 - g_loss: 0.8363\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 40s 3s/step - d_loss: 0.6775 - g_loss: 0.8370\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 40s 3s/step - d_loss: 0.6754 - g_loss: 0.8375\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 41s 3s/step - d_loss: 0.6772 - g_loss: 0.8382\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 34s 3s/step - d_loss: 0.6762 - g_loss: 0.8388\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 23s 2s/step - d_loss: 0.6759 - g_loss: 0.8394\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 28s 2s/step - d_loss: 0.6749 - g_loss: 0.8401\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 24s 2s/step - d_loss: 0.6745 - g_loss: 0.8409\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 26s 2s/step - d_loss: 0.6755 - g_loss: 0.8416\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 25s 2s/step - d_loss: 0.6756 - g_loss: 0.8420\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 33s 3s/step - d_loss: 0.6764 - g_loss: 0.8426\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 31s 2s/step - d_loss: 0.6756 - g_loss: 0.8431\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 42s 3s/step - d_loss: 0.6757 - g_loss: 0.8438\n"
     ]
    }
   ],
   "source": [
    "hist = loadgan.fit(ds_w, epochs=100, callbacks=[ModelMonitor()])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T21:12:47.011348800Z",
     "start_time": "2024-02-13T20:21:41.776826400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Feri\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'sequential_36' (type Sequential).\n\nInput 0 of layer \"lstm_67\" is incompatible with the layer: expected shape=(None, None, 15), found shape=(4, 96, 1)\n\nCall arguments received by layer 'sequential_36' (type Sequential):\n  • inputs=tf.Tensor(shape=(4, 96, 1), dtype=float32)\n  • training=False\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[104], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m normal_noise \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mnormal((\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m96\u001B[39m, \u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m----> 2\u001B[0m series \u001B[38;5;241m=\u001B[39m \u001B[43mgenerator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnormal_noise\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m resolution \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m24\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m4\u001B[39m\n\u001B[0;32m      4\u001B[0m ticks \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py:295\u001B[0m, in \u001B[0;36massert_input_compatibility\u001B[1;34m(input_spec, inputs, layer_name)\u001B[0m\n\u001B[0;32m    293\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m spec_dim \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m dim \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    294\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m spec_dim \u001B[38;5;241m!=\u001B[39m dim:\n\u001B[1;32m--> 295\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    296\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mInput \u001B[39m\u001B[38;5;132;01m{\u001B[39;00minput_index\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m of layer \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlayer_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m is \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    297\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mincompatible with the layer: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    298\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexpected shape=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mspec\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    299\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound shape=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdisplay_shape(x\u001B[38;5;241m.\u001B[39mshape)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    300\u001B[0m         )\n",
      "\u001B[1;31mValueError\u001B[0m: Exception encountered when calling layer 'sequential_36' (type Sequential).\n\nInput 0 of layer \"lstm_67\" is incompatible with the layer: expected shape=(None, None, 15), found shape=(4, 96, 1)\n\nCall arguments received by layer 'sequential_36' (type Sequential):\n  • inputs=tf.Tensor(shape=(4, 96, 1), dtype=float32)\n  • training=False\n  • mask=None"
     ]
    }
   ],
   "source": [
    "normal_noise = tf.random.normal((4, 96, 15))\n",
    "series = generator.predict(normal_noise)\n",
    "resolution = 24*4\n",
    "ticks = []\n",
    "'''for i in range(resolution):\n",
    "    if i%4 == 0:\n",
    "        ticks.append(str(int(i/4)))\n",
    "    else:\n",
    "        ticks.append('')'''\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 4), dpi=200)\n",
    "for s in series:\n",
    "    ax[0].plot(range(resolution), np.multiply(s.reshape([resolution]), max_w), linewidth=1)\n",
    "ax[0].set_xlabel('Hour of Day')\n",
    "ax[0].set_ylabel('Generated Power Consumption')\n",
    "ax[0].set_xticks(range(resolution), ticks)\n",
    "\n",
    "ax[1].plot(my_data[[c for c in my_data.columns[:30] if 'weekday' in c]], linewidth=1)\n",
    "ax[1].set_xlabel('Hour of Day')\n",
    "ax[1].set_ylabel('Historical Power Consumption')\n",
    "ax[1].set_xticks(range(resolution), ticks)\n",
    "plt.show()\n",
    "#plt.savefig(f'../HarrisCounty/IMG/Batch {batch_size}-g_a {g_a}-d_a {d_a}-relu {g_relu}-dropout {d_dropout}.jpg')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T20:13:07.590635700Z",
     "start_time": "2024-02-13T20:13:07.471530700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.27908119, 0.2759418 , 0.27463341, 0.27405271, 0.27432569,\n       0.27313007, 0.27858002, 0.27364891, 0.27608115, 0.27181148,\n       0.27016231, 0.27060353, 0.27004301, 0.26987569, 0.27066322,\n       0.27330752, 0.2778053 , 0.28101921, 0.28935684, 0.29437885,\n       0.30389723, 0.33307793, 0.34405041, 0.36289508, 0.38296953,\n       0.3904404 , 0.30405398, 0.32075887, 0.33629515, 0.33731308,\n       0.35428984, 0.36416878, 0.38175299, 0.387709  , 0.40770009,\n       0.41751363, 0.50162191, 0.47434448, 0.52666341, 0.53291421,\n       0.56093852, 0.58824933, 0.60970465, 0.64027751, 0.65239148,\n       0.66913008, 0.67112885, 0.67677692, 0.68230252, 0.69032767,\n       0.69878317, 0.70485187, 0.7038729 , 0.70826203, 0.71423653,\n       0.7212561 , 0.72012173, 0.72302043, 0.71559406, 0.70867889,\n       0.69856939, 0.69000608, 0.65998895, 0.63536303, 0.62621779,\n       0.61607444, 0.58153808, 0.570353  , 0.53930612, 0.50313002,\n       0.48843719, 0.4723261 , 0.46238534, 0.44552964, 0.40714386,\n       0.37695569, 0.35834097, 0.34849895, 0.33231082, 0.31478659,\n       0.29779826, 0.41972983, 0.40731824, 0.39458549, 0.32497749,\n       0.3254483 , 0.32290059, 0.32131586, 0.31488327, 0.31134908,\n       0.31161605, 0.30322966, 0.29606734, 0.29248199, 0.29011328,\n       0.288225  ])"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_w.as_numpy_iterator().next()[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T20:04:08.635122400Z",
     "start_time": "2024-02-13T20:04:08.577821500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 500x300 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 3), dpi=100)\n",
    "plt.suptitle('Loss')\n",
    "plt.plot(hist.history['d_loss'], label='Discriminator Loss')\n",
    "plt.plot(hist.history['g_loss'], label='Generator Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T20:09:56.155907100Z",
     "start_time": "2024-02-13T20:09:56.017711500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator.save('generator.h5')\n",
    "discriminator.save('discriminator.h5')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
